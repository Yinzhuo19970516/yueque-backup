# 操作系统笔记
# 第一章

## 操作系统主要模块

ＣＰＵ的调度  
物理内存管理  
虚拟内存管理  
文件系统管理  
中断处理与设备驱动

## 操作系统主要特征

并发  
共享  
虚拟  
异步

# 第二章

操作系统与设备程序交互  
面向外设通过中断 I/0 处理  
面向程序通过系统调用和异常处理  
优点：方便应用程序调用

## 中断

概念：外设操作引起中断  
处理过程  
硬件：标记中断号  
软件：保存当前被打断进进程的执行处理状态  
中断服务程序处理  
清楚中断标记  
恢复之前保存的处理状态

## 异常：

概念：程序意想不到的行为  
处理过程  
保存现场  
异常处理（杀死程序，或者重新执行指令）  
恢复现场（重新执行指令）

## 系统调用：

概念：应用程序主动向 os 发出请求，申请资源（设备管理，文件管理，进程管理，进程通信，内存管理）  
处理过程  
处理过程  
用户态到内核态的转化（内核态可以调用很多特殊指令，完全控制整个操作系统，开销更大）  
控制权从应用程序到操作系统

# 第三章

## 计算机原理回顾

**计算机基本硬件结构** CPU 内存 设备  
**内存层次结构**（cpu 访问的数据在哪里） 寄存器 cache 物理内存 硬盘

## 操作系统操作内存的要实现的目标

抽象 逻辑地址空间  
保护 独立的地址空间  
共享 访问相同内存  
虚拟化 更多的地址空间

## 操作系统中管理内存的不同方法

程序重定位  
分段  
分页  
虚拟内存  
按需分页虚拟内存

## 地址空间&地址生成

物理地址空间：硬件支持的地址空间  
逻辑地址空间：一个运行的程序拥有的内存范围  
逻辑地址生成：编译 汇编 链接 载入  
逻辑地址和物理地址有映射关系，映射关系存储在内存中  
操作系统做的事情在于建立映射表

### 连续内存分配

**内存碎片问题**（外部碎片，内部碎片）

### 分配策略

#### 首次适配：

- 实现：
  - 按尺寸排列空闲块
  - 把第一个符合条件的空闲块给分配给应用程序
  - 回收时会合并空闲块，产生更大的空闲块
- 优点：
  - 简单
  - 易于产生更大的空闲块，向着地址空间的结尾
- 缺点
  - 在回收合并的过程中，容易产生外部碎步

#### 最优适配

- 实现：
  - 按尺寸排列空闲块
  - 寻找差值最小的空闲块
  - 重新分配需要搜索合并相邻的空闲块
- 优点：
  - 简单
  - 当大部分分配是小尺寸非常有效
- 缺点：
  - 重分配慢
  - 易产生没用的微小碎步

#### 最差适配

- 实现：
  - 按尺寸排列空闲块
  - 寻找差值最大的空闲块
  - 重分配合并相邻空闲分区
- 优势：
  - 如果分配是中等尺寸效果最好
- 劣势：
  - 易于破碎大空闲块，导致大分区无法分配
  - 没有最好的策略，因地制宜

### 压缩式碎片处理

挪动，紧致程序占用的空间，形成大的连续空闲块

### 交换式碎片整理

运行时程序需要更多内存  
抢占等待的程序 & 回收他们的空间（从主存-> 磁盘）

# 第四章

## 为什么需要非连续内存分配

连续内存分配方式或多或少都会有内外碎片问题

## 两种硬件方案

### 分段

逻辑地址空间分散到多个物理地址空间，连续的逻辑地址被分成了不连续的物理地址空间

### 分段寻址方案

段号 + 段内偏移地址  
通过段表，去查找段号对应的物理地址，段表由操作系统建立  
通过偏移地址，去找具体所在段

### 分页

分页是大部分 os 主流方案  
划分物理内存只固定大小的帧，划分逻辑地址空间至大小相同的页

### 分页寻址方案

页号 + 页内偏移  
通过页表，去查找对应的帧号  
通过帧号+偏移量，去查找物理地址

## 怎么去实现页表相互转换

### 分页机制性能问题

访问一个内存单元需要 2 次内存访问  
一个获取页表项  
一个访问数据  
页表可能会很大

### 时间开销减小

缓存近期访问的页帧转换表项 TLB  
快表 TLB 存放在 CPU 中，具备快速访问性能，每次先检查 TLB 是否命中

### 空间开销减小

多级页表方案  
一级目录变成多级目录，多了一次查表，使得页表变小，非关键信息可以放二级页表，类似 DNS 查询过程，树型结构。

### 大地址空间问题，出现深层级页表

对于 32 位机器采用多级页表勉强足够存储页表项，但是对于 64 位机器，那总地址空间大小为 2^64，如果每个页面大小是 4K，那么就需要 2^64/4K=2^64/2^12=2^52 数目的页面，这个如果只用一级页表，在内存中用指针存储的话，按每个指针 4byte，那就一共要 4\*2^52=2^56byte，远超过目前的物理内存量级，所以在内存里存不下，即使采用 5 级页表也难以存储下这么多地址。  
反向页表  
正常页表结构，一个进程就会有一个页表，反向页表表存储的是一个通用表，映射是物理地址，值是逻辑地址。至于怎么转换，老师没讲清楚，我也没有理解

# 第五章

## 虚拟内存的起因

经常出现内存不够用的情况，程序规模增长大于存储器容量的增长  
理想的存储器：更大，更快，更便宜，非易失性存储  
不常用的放在硬盘上，常用的放在内存上  
计算机系统，多道程序运行的环境中，内存不够用的解决方案

## 覆盖技术

目标：  
出现在 80 年代，比较小的内存运行比较大的程序  
思路：  
程序按功能划分模块，常用模块，不常用模块，常用模块在内存中，不常用模块在外存中，需要时在放入内存执行。无调用关系的模块，分时装入内存可以直接覆盖，按时间顺序执行。  
缺点：  
程序设计太复杂

## 交换技术

目标：  
让正在运行的程序或者需要运行的程序获取更多的内存资源  
思路：  
将暂时不能运行的程序送到外存，从而获得更多的内存空间  
换入换出  
难点：  
交换时机不好确定  
交换空间的大小不好确定

## 虚存技术

虚拟内存管理技术

### 目标：

结合覆盖技术和交换技术的优点

### 程序的局部性原理：

程序在执行的一个较短时间，所执行的指令和指令操作数地址分别局限与一个区域  
程序局部性原理表面，理论上，虚拟内存技术是可行的

### 基本概念：

可以在页式或者段式内存管理的基础上实现  
只需将当前需要执行的部分分页或者分段放入内存  
出现缺页或者缺段是，再把页或者段调入内存  
也可以把不需要的页和段保存在外存中

### 基本特征：

大的用户空间  
部分交换  
不连续：物理地址分配不连续，虚拟地址空间使用不连续

### 请求调页&页面置换功能

**页表表项**  
**逻辑页号+访问位 + 保护位 +修改位 + 驻留位 +物理页帧号**  
访问位：是否被访问过，后续页面置换算法会用到  
保护位：访问权限  
修改位：是否被修改过  
驻留位：所在位置，内存或者外存，如果访问这个，说明出现缺页中断

# 第六章

## 页面置换算法概述

### 功能：

当出现缺页中断，需要调入新的页面，内存已经满了，应该选择哪个页面被置换

### 目标：

尽可能减少页面换进换出的次数（即缺页中断次数）

## 置换算法策略

### 最优页面置换算法

**思路**：  
选择下一次访问还需要等待时间最长的页面置换  
**实际**：  
获得下一次访问的时机，实际操作太难，太过理想化，但是可以做为其他算法的对比标准  
**先进先出算法 FIFO**  
**思路**：  
选择在内存中驻留时间最长的页面并置换  
维护一个链表，新加页面增加到链表尾部，老得页面在头部。  
**实际：**  
页面很多，性能较差，很少单独使用

### 最近最久未使用页面算法 LRU

**思路**：  
最优页面置换算法的一个近似，如果过去很长时间没有被访问，则被替换  
**实际**：  
需要记录各个页面使用时间的先后顺序  
开销比较大，可能的实现方案  
维护一个栈，当访问某页时，将此页号压入栈顶，然后考察栈内是否有于此相同的页号，若有则抽出，当需要淘汰一个页面时，总是选择栈低元素

### 时钟页面置换算法 Clock

思路：  
LRU 的近似，FIFO 的改进  
需要用到页表项的访问位，当页面被装入内存，该位初始化为 0，如果这个页面被访问，该位置置 1（硬件完成）  
操作系统定期清 0（探测过就清 0），把各个页面组织成环形结构，把指针指向最老的页面（为 0 的页面）

### 二次机会法

时钟算法，只要被读或者被写都认为被访问，开销很大  
区分读和写操作，同时使用修改位和访问位来区分，如果修改位和访问位都是 0，则必须替换，如果修改位是 1，访问位都是 1，那么修改位不变，访问位置为 1。  
总结就是，只读的页面优先替换

### 最不常用算法 LFU

**思路**：  
缺页中断时，选择访问次数最少的那个页面，并淘汰  
**实现：**  
对每个页面增加一个访问计数器，当访问时，计数器加一  
LRU 关注时间，LFU 关心次数  
当出现某个程序某个时间段多次使用，之后再不使用，此时 LFU 不靠谱，所以需要定时计数器清除

## Belay 现象

当使用 FIFO 算法时，有时会出现分配的物理页面数增加，缺页率反而提高的现象  
程序访问是动态的，如果暴力的替换，先进先出，不符合程序动态的原则  
LRU 不会有这种现象

## 局部页面置换算法的问题

操作系统会同时运行多个程序，分配的物理页帧也是动态的

## 工作集模型

工作集：一个进程当前使用的逻辑页面集合  
常驻集： 当前时刻，进程实际驻留在内存中的页面集合

## 两个全局置换算法：

基于缺页率的页面置换算法  
策略：常驻集大小可变，缺页率高的进程，多分配物理页面  
缺页率 = 缺页次数/内存访问次数  
我理解就是滑动窗口拉长，缺页率高的时候，增加工作集，缺页率低的时候，减少工作集

## 抖动问题

如果分配的常驻集远远小于工作集，会频繁出现缺页中断，需要频繁在内存外存之间替换页面，从而使得进程运行很慢，我们把这种叫做抖动问题

# 第七章：进程管理

## 进程的描述

### 定义

一个具有一定独立功能的程序在以恶搞数据集合上一次动态执行过程

### 进程的组成

代码，处理的数据，堆栈信息，系统资源等，正在运行的程序的所有信息

### 进程的特点

动态性：可动态的创建结束  
并发性：可并发（一段时间） 区别并行的概念（同一时刻）  
独立性：不同进程的工作互不影响  
制约性：因访问共享数据或者进程间同步会有互斥制约

### 进程控制块

描述进程的数据结构：进程控制块 PCB process control block  
主要包括三部分信息  
进程标识信息： 如本进程的产生标识，产生者标识，用户标识  
处理机状态信息保存区：  
用户可见的寄存器  
控制和状态寄存器  
堆栈信息  
进程控制信息  
调度和状态信息  
进程间的通信信息  
存储管理信息  
进程所用资源  
PCB 的组织方式：链表和索引表

### 进程的状态

#### 进程声明周期管理

- 进程创建

系统初始化时  
用户请求创建一个新程序时  
正在运行的进程执行了创建进程的系统调用

- 进程运行

内核选择一个就绪的进程，让它占用处理机并执行

- 进程等待（阻塞）

异步操作依赖结果   
 进程只能自己阻塞自己，因为只有进程自己知道何时需要等待

- 进程唤醒

拿到异步数据

- 进程结束

正常退出  
错误退出  
致命错误  
被其他进程关闭

#### 进程三个基本状态

- 运行状态 running
- 就绪状态 ready
- 等待状态 blocked
- 其他基本状态 创建状态 new 结束状态 exit

#### 进程挂起

进程没有占用内存空间，处于挂起状态的进程映像在磁盘上  
挂起就是把一个进程从内存转到外存  
激活/解挂 就是把进程从外存转到内存

#### 状态队列：

就绪队列 阻塞队列 不同到状态用不同的队列维护

## 线程管理

### 为什么使用线程

有并发执行的场景  
且需要共享共同的地址空间，所以进程不合适了，提出了新的概念

### 什么是线程

进程当中的一条执行流程  
Thread control block TCB  
线程 = 进程 - 共享资源  
一个进程可同时存在多条线程，可并发执行，共享地址空间和文件资源  
一个线程崩溃，会导致其他线程全部 gg

### 线程和进程的比较

进程是资源分配单位，线程是 CPU 调度单位  
进程拥有一个完整的资源平台  
线程同样具有就绪，阻塞，执行三个状态  
线程能减少并发执行的空间和时间开销  
**进程间通信**  
上下文切换  
概念：停止当前运行进程并且调度其他进程  
进程上下文：寄存器，CPU 状态  
进程切换上下文开销很大，尽量避免

# 第八章 调度

## 背景

CPU 调度：从就绪队列选择某个进程/线程作为 CPU 下一个要运行第进程/线程。  
调度的时机：经过运行态的状态变化都是进行调度  
调度的两个策略：  
不可抢占（需要等待上一个执行完，效率不高）  
可以抢占（有操作系统来决定是否可可以执行）

## 调度原则

评价指标：

- CPU 利用率：cpu 处于忙碌状态所占的百分比：越高越好
- 吞吐率：单位时间内完成进程的数量：越高越好
- 周转时间：一个进程从初始化到结束，包括所有等待时间所花费的时间：越短越好
- 等待时间：进程在就绪队列中的总时间：越短越好
- 响应时间：从一个请求被提交到产生第一次相应所花费的总时间：越短越好
- 减小平均响应时间的波动

## 调度算法

### FCFS 先来先服务

故名思议，维护进程队列，先来先执行  
优势：简单  
缺点：平均等待时间波动大  
 没有考虑抢占情况  
**总结：不公平，平均等待时间较差**

### SPN 短进程优先

执行时间排序，或者按等待时间排序，可以是抢占的也可以是不可抢占的，  
优点：平均等待时间最小  
缺点：持续短任务导致长任务饥饿  
 需要预知未来，预知执行时间（可以根据历史执行情况来推断）  
**总结：不公平，但是平均等待时间最小**  
**需要精确预测计算时间**  
**可能导致饥饿**

### HRRN 最高响应比优先

在 spn 的基础上改造，不可抢占  
关注进程等待了多长时间  
R = (等待时间+执行时间)/执行时间  
R 越大，越需要执行  
**总结：基于 SPN 调度改进**  
**不可抢占**

### Round Robin 轮询算法

让各个进程轮流占用 CPU 去执行  
可定义一个时间片，轮流执行，每个进程都有机会占用 CPU,相当公平  
缺点：上下文切换很多  
 时间片大小不好把握  
**总结：公平，但是平均等待时间较差**

### MLPQ 多级反馈队列

把进程分成独立队列  
每个队列拥有自己的调度策略  
根据进程的特点来选择调度算法  
因为进程是动态的，所以需要支持一个进程可以在不同的队列中移动  
**总结：和 SPN 类似**

## 实时调度

### 实时系统

火车 机床 规定时间内必须完成任务的系统  
时间是确定的  
速度和性能相对不重要

## 多处理器调度

## 优先级反转

# 同步

## 背景介绍

多核程序 在调度过程中，存在不确定性因素，因此引入同步互斥机制，来解决这个问题

## 一些概念

### 竞态条件

结果依赖于并发执行或者事件的顺序/时间  
怎么避免竞态 让指令不被打断

### 原子操作

不可被打断的操作  
饥饿 死锁 临界区 互斥

## 临界区

### 特点

- 互斥：同一临界区中最多存在 1 个线程
- Progress:如果一个线程想进入临界区，最终能成功进入进入
- 有限等待
- 无忙等待：等待时可以被挂起

## 禁用硬件中断

- 中断强制打断进程执行，进程切换
- 进入临界区 禁用中断
- 离开临界区 恢复中断

### 问题

- 中断禁用，线程无法停止
- 临界区时长不确定
- 无法中断其他 CPU
- 适用于 单核操作系统

## 基于软件解决办法

复杂

# 第十章

## 信号量

### 抽象数据类型

- 一个整形 sem 两个原子操作
  - P() ：sem-1 如果 sem <0 等待，否则继续
  - V(): sem+1，如果 sem<=0 唤醒一个等待的进程

## 信号量的使用

- 互斥
- 条件约束

## 信号量的实现

## 管程

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1572912/1658708776186-3e303dbb-3c3b-4e3b-92fd-a3a055b51353.png#averageHue=%23fefefe&clientId=u72c524fd-9e17-4&from=paste&height=267&id=u65b55939&originHeight=534&originWidth=970&originalType=binary&ratio=1&rotation=0&showTitle=false&size=189670&status=done&style=none&taskId=u2812b4ba-85bb-4264-8e8b-f039673d9bd&title=&width=485)

<br>
  
> 语雀地址 https://www.yuque.com/yuqueyonghuyv23kd/zxkn1f/rq4rgt